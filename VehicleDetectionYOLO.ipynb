{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Flatten, Dense, Activation, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_dim_ordering('th')\n",
    "\n",
    "def YOLOTrainedModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Conv2D(16, (3, 3), input_shape=(3, 448, 448), strides=(1, 1), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    \n",
    "    # Layer 3\n",
    "    model.add(Conv2D(64,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    \n",
    "    # Layer 4\n",
    "    model.add(Conv2D(128,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    \n",
    "    # Layer 5\n",
    "    model.add(Conv2D(256,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    \n",
    "    # Layer 6\n",
    "    model.add(Conv2D(512,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    \n",
    "    # Layer 7\n",
    "    model.add(Conv2D(1024,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    # Layer 8\n",
    "    model.add(Conv2D(1024,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    # Layer 9\n",
    "    model.add(Conv2D(1024,(3,3) ,padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Layer 10\n",
    "    model.add(Dense(256))\n",
    "    \n",
    "    # Layer 11\n",
    "    model.add(Dense(4096))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    # Layer 12\n",
    "    model.add(Dense(1470))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 448, 448)      448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 448, 448)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 224, 224)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 224, 224)      4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 224, 224)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 112, 112)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 56, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 56, 56)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 28, 28)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 256, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 14, 14)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1024, 7, 7)        4719616   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 1024, 7, 7)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 1024, 7, 7)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 1024, 7, 7)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1470)              6022590   \n",
      "=================================================================\n",
      "Total params: 45,089,374\n",
      "Trainable params: 45,089,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "YOLOTrainedModel().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, yolo_weight_file):\n",
    "    data = np.fromfile(yolo_weight_file, np.float32)\n",
    "    data = data[4:]\n",
    "\n",
    "    index = 0\n",
    "    for layer in model.layers:\n",
    "        shape = [w.shape for w in layer.get_weights()]\n",
    "        if shape != []:\n",
    "            kshape, bshape = shape\n",
    "            bia = data[index:index + np.prod(bshape)].reshape(bshape)\n",
    "            index += np.prod(bshape)\n",
    "            ker = data[index:index + np.prod(kshape)].reshape(kshape)\n",
    "            index += np.prod(kshape)\n",
    "            layer.set_weights([ker, bia])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingTestImage(image):\n",
    "    \n",
    "    imageCrop = image[300:650,500:,:]\n",
    "    resizing = cv2.resize(imageCrop,(448,448))\n",
    "    preprocessed = np.transpose(resizing,(2,0,1))\n",
    "    preprocessed = 2*(preprocessed/255.) - 1\n",
    "    preprocessed = np.expand_dims(preprocessed, axis=0)\n",
    "    \n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on:\n",
    "# YAD2K https://github.com/allanzelener/YAD2K\n",
    "# darkflow https://github.com/thtrieu/darkflow\n",
    "# Darknet.keras https://github.com/sunshineatnoon/Darknet.keras\n",
    "# https://github.com/xslittlegrass/CarND-Vehicle-Detection\n",
    "\n",
    "# Box util methods\n",
    "\n",
    "class Box:\n",
    "    def __init__(self):\n",
    "        self.x, self.y = float(), float()\n",
    "        self.w, self.h = float(), float()\n",
    "        self.c = float()\n",
    "        self.prob = float()\n",
    "        \n",
    "def overlap(x1, w1, x2, w2):\n",
    "    l1 = x1 - w1 / 2.\n",
    "    l2 = x2 - w2 / 2.\n",
    "    left = max(l1, l2)\n",
    "    r1 = x1 + w1 / 2.\n",
    "    r2 = x2 + w2 / 2.\n",
    "    right = min(r1, r2)\n",
    "    return right - left\n",
    "\n",
    "\n",
    "def box_intersection(a, b):\n",
    "    \"\"\"\n",
    "\n",
    "    :param a: Box 1\n",
    "    :param b: Box 2\n",
    "    :return: Intersection area of the 2 boxes\n",
    "    \"\"\"\n",
    "    w = overlap(a.x, a.w, b.x, b.w)\n",
    "    h = overlap(a.y, a.h, b.y, b.h)\n",
    "    if w < 0 or h < 0:\n",
    "        return 0\n",
    "    area = w * h\n",
    "    return area\n",
    "\n",
    "\n",
    "def box_union(a, b):\n",
    "    \"\"\"\n",
    "\n",
    "    :param a: Box 1\n",
    "    :param b: Box 2\n",
    "    :return: Area under the union of the 2 boxes\n",
    "    \"\"\"\n",
    "    i = box_intersection(a, b)\n",
    "    u = a.w * a.h + b.w * b.h - i\n",
    "    return u\n",
    "\n",
    "\n",
    "def box_iou(a, b):\n",
    "    \"\"\"\n",
    "\n",
    "    :param a: Box 1\n",
    "    :param b: Box 2\n",
    "    :return: Intersection over union, which is ratio of intersection area to union area of the 2 boxes\n",
    "    \"\"\"\n",
    "    return box_intersection(a, b) / box_union(a, b)\n",
    "\n",
    "\n",
    "\n",
    "def yolo_output_to_car_boxes(yolo_output, threshold=0.1, sqrt=1.8, C=20, B=2, S=7):\n",
    "\n",
    "    # Position for class 'car' in the VOC dataset classes\n",
    "    car_class_number = 6\n",
    "\n",
    "    boxes = []\n",
    "    SS = S*S  # number of grid cells\n",
    "    prob_size = SS*C  # class probabilities\n",
    "    conf_size = SS*B  # confidences for each grid cell\n",
    "\n",
    "    probabilities = yolo_output[0:prob_size]\n",
    "    confidence_scores = yolo_output[prob_size: (prob_size + conf_size)]\n",
    "    cords = yolo_output[(prob_size + conf_size):]\n",
    "\n",
    "    # Reshape the arrays so that its easier to loop over them\n",
    "    probabilities = probabilities.reshape((SS, C))\n",
    "    confs = confidence_scores.reshape((SS, B))\n",
    "    cords = cords.reshape((SS, B, 4))\n",
    "\n",
    "    for grid in range(SS):\n",
    "        for b in range(B):\n",
    "            bx = Box()\n",
    "\n",
    "            bx.c = confs[grid, b]\n",
    "\n",
    "            # bounding box xand y coordinates are offsets of a particular grid cell location,\n",
    "            # so they are also bounded between 0 and 1.\n",
    "            # convert them absolute locations relative to the image size\n",
    "            bx.x = (cords[grid, b, 0] + grid % S) / S\n",
    "            bx.y = (cords[grid, b, 1] + grid // S) / S\n",
    "\n",
    "\n",
    "            bx.w = cords[grid, b, 2] ** sqrt\n",
    "            bx.h = cords[grid, b, 3] ** sqrt\n",
    "\n",
    "            # multiply confidence scores with class probabilities to get class sepcific confidence scores\n",
    "            p = probabilities[grid, :] * bx.c\n",
    "\n",
    "            # Check if the confidence score for class 'car' is greater than the threshold\n",
    "            if p[car_class_number] >= threshold:\n",
    "                bx.prob = p[car_class_number]\n",
    "                boxes.append(bx)\n",
    "\n",
    "    # combine boxes that are overlap\n",
    "\n",
    "    # sort the boxes by confidence score, in the descending order\n",
    "    boxes.sort(key=lambda b: b.prob, reverse=True)\n",
    "\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        boxi = boxes[i]\n",
    "        if boxi.prob == 0:\n",
    "            continue\n",
    "\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            boxj = boxes[j]\n",
    "\n",
    "            # If boxes have more than 40% overlap then retain the box with the highest confidence score\n",
    "            if box_iou(boxi, boxj) >= 0.4:\n",
    "                boxes[j].prob = 0\n",
    "\n",
    "    boxes = [b for b in boxes if b.prob > 0]\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def draw_boxes(boxes,im, crop_dim):\n",
    "    imgcv1 = im.copy()\n",
    "    [xmin, xmax] = crop_dim[0]\n",
    "    [ymin, ymax] = crop_dim[1]\n",
    "    \n",
    "    height, width, _ = imgcv1.shape\n",
    "    for b in boxes:\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "\n",
    "        left  = int ((b.x - b.w/2.) * w) + xmin\n",
    "        right = int ((b.x + b.w/2.) * w) + xmin\n",
    "        top   = int ((b.y - b.h/2.) * h) + ymin\n",
    "        bot   = int ((b.y + b.h/2.) * h) + ymin\n",
    "\n",
    "        if left  < 0:\n",
    "            left = 0\n",
    "        if right > width - 1:\n",
    "            right = width - 1\n",
    "        if top < 0:\n",
    "            top = 0\n",
    "        if bot>height - 1: \n",
    "            bot = height - 1\n",
    "        \n",
    "        thick = 5 #int((height + width // 150))\n",
    "        \n",
    "        cv2.rectangle(imgcv1, (left, top), (right, bot), (255,0,0), thick)\n",
    "\n",
    "    return imgcv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOTrainedModel()\n",
    "load_weights(model,'yolo-tiny.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1470)\n",
      "[]\n",
      "(1, 1470)\n",
      "[]\n",
      "(1, 1470)\n",
      "[]\n",
      "(1, 1470)\n",
      "[]\n",
      "(1, 1470)\n",
      "[]\n",
      "(1, 1470)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for image in glob.glob('test_images/test*.jpg'):\n",
    "    \n",
    "    image = mpimg.imread(image)\n",
    "    imagePreprocess=preprocessingTestImage(image)\n",
    "    test_output = model.predict(imagePreprocess)\n",
    "    print(test_output.shape)\n",
    "    boxes = yolo_output_to_car_boxes(test_output[0],threshold = 0.25)\n",
    "    print(boxes)\n",
    "    final = draw_boxes(boxes, image, ((500,1280),(300,650)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
